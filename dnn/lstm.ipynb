{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwxfNuM527Vn",
        "outputId": "72af8c74-56fb-42a4-9a25-8e61140000c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow pandas tqdm scikit-learn gensim Sastrawi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1q0VtJJ21We"
      },
      "source": [
        "# LSTM Implementation\n",
        "\n",
        "In this LSTM implementation endeavor, we looking into the implementation of LSTM-based model to do sentiment analysis for case below:\n",
        "\n",
        "https://www.kaggle.com/code/kevinismail/training-lstm-sentiment-analysis-bahasa\n",
        "\n",
        "This endeavor aim to create an LSTM model with high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZpZSbE321Wi"
      },
      "outputs": [],
      "source": [
        "import tensorflow;\n",
        "\n",
        "import pandas;\n",
        "from sklearn.model_selection import train_test_split;\n",
        "from tqdm import tqdm;\n",
        "import re;\n",
        "\n",
        "import json;\n",
        "\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ekFhK1O3VQa",
        "outputId": "8e361332-e55f-4bdf-ed42-ec0e669996e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive;\n",
        "drive.mount(\"/content/drive\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5usV7lbf21Wk"
      },
      "source": [
        "## Data Loading & Exploration\n",
        "\n",
        "First is to load the dataset with pandas. The file separator is [TAB] so we set it to `\\\\t+`.\n",
        "\n",
        "This part also explore the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "hxalWPcZ21Wk",
        "outputId": "fcfc823b-be84-4bf5-eef4-c44f4202d0b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-b221262af985>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  dataframe = pandas.read_csv(\"/content/drive/MyDrive/Collab Dataset/nlp-dl-self-assignment/raw_dataset.csv\", sep = \"\\\\t+\");\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Profile Model\n",
            "============================================================\n",
            "sentimen    10806\n",
            "Tweet       10806\n",
            "dtype: int64\n",
            "Data with sentiment negative (-1) \t: 2887\n",
            "Data with sentiment neutral (0)   \t: 5327\n",
            "Data with sentiment positive (1)  \t: 2592\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataframe\",\n  \"rows\": 10806,\n  \"fields\": [\n    {\n      \"column\": \"sentimen\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10090,\n        \"samples\": [\n          \"tuips kampanye dah dimulai ya yuks viralkan lg janji2 kampanye pak de 2014 anggarannya ada tinggal mau dikibuli\",\n          \"aku tahu kau boleh sabar k\",\n          \"saya selaku admin peleksana event 2tahunipintinioi meminta maaf yang sebesar besarnya untuk anak anak dikarenaka\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d495a075-6713-4203-a201-5d9d657dda28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentimen</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>lagu bosan apa yang aku save ni huhuhuhuhuhuhu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>kita lanjutkan saja diam ini hingga kau dan ak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>doa rezeki tak putus inna haa zaa larizquna ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>makasih loh ntar kita bagi hasil aku 99 9 sisa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>aku tak faham betul jenis orang malaysia yang ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d495a075-6713-4203-a201-5d9d657dda28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d495a075-6713-4203-a201-5d9d657dda28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d495a075-6713-4203-a201-5d9d657dda28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3cd2ec9a-0d08-46ad-82df-83d68676a1ca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3cd2ec9a-0d08-46ad-82df-83d68676a1ca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3cd2ec9a-0d08-46ad-82df-83d68676a1ca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   sentimen                                              Tweet\n",
              "0        -1  lagu bosan apa yang aku save ni huhuhuhuhuhuhu...\n",
              "1        -1  kita lanjutkan saja diam ini hingga kau dan ak...\n",
              "2         1  doa rezeki tak putus inna haa zaa larizquna ma...\n",
              "3         1  makasih loh ntar kita bagi hasil aku 99 9 sisa...\n",
              "4        -1  aku tak faham betul jenis orang malaysia yang ..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe = pandas.read_csv(\"/content/drive/MyDrive/Collab Dataset/nlp-dl-self-assignment/raw_dataset.csv\", sep = \"\\\\t+\");\n",
        "\n",
        "\n",
        "print(\"Data Profile Model\");\n",
        "print(\"============================================================\");\n",
        "print(dataframe.count());\n",
        "\n",
        "sentiment_negative = len(dataframe[dataframe[\"sentimen\"] == -1]);\n",
        "sentiment_neutral = len(dataframe[dataframe[\"sentimen\"] == 0]);\n",
        "sentiment_positive = len(dataframe[dataframe[\"sentimen\"] == 1]);\n",
        "print(f\"Data with sentiment negative (-1) \\t: {sentiment_negative}\");\n",
        "print(f\"Data with sentiment neutral (0)   \\t: {sentiment_neutral}\");\n",
        "print(f\"Data with sentiment positive (1)  \\t: {sentiment_positive}\");\n",
        "\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cebEqZCu21Wm"
      },
      "source": [
        "# Train-Test-Split\n",
        "\n",
        "The ratio used in this project will be 7 : 1,5 : 1,5\n",
        "\n",
        "| Segment | Ratio |\n",
        "|---|---|\n",
        "| `train` | 7 |\n",
        "| `test` | 1,5 |\n",
        "| `val` | 1,5 |\n",
        "\n",
        "This can be done by applying the following algorithm below:\n",
        "\n",
        "> 1. Apply train-test split to whole data by 7 for train and 3 for the rest\n",
        "> 2. Apply train-test split to \"rest\" data by 5 for first half and 5 for the second half\n",
        "\n",
        "This will split the data into 7 : 1,5 : 1,5 ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vViJbK4u21Wm"
      },
      "outputs": [],
      "source": [
        "features = dataframe[\"Tweet\"];\n",
        "labels = dataframe[\"sentimen\"];\n",
        "\n",
        "# Splitting data for training and testing & Validation\n",
        "# First is to split the data into 7 : 3\n",
        "feature_train, feature_test, label_train, label_test = train_test_split(\n",
        "    features,\n",
        "    labels,\n",
        "    train_size = 0.7,\n",
        "    test_size = 0.3, # test and val\n",
        "    random_state = 42\n",
        ");\n",
        "\n",
        "# With 3 of 10 portion left, then to split the data into 1,5 : 1,5, we can do 0,5 : 0,5\n",
        "feature_test, feature_val, label_test, label_val = train_test_split(\n",
        "    feature_test, # Taken from line 6\n",
        "    label_test, # Taken from line 6\n",
        "    train_size = 0.5,\n",
        "    test_size = 0.5,\n",
        "    random_state = 42\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9TtU8j421Wn"
      },
      "source": [
        "## Dataset Pre-Processing\n",
        "\n",
        "NLP / NLU cases are known as not easy dataset pre-processing. <br />\n",
        "Imagine converting your text into numbers just to make computer understand what you try to do. <br />\n",
        "Public dataset also challenging. <br />\n",
        "I mean, what is this? Bahasa Indonesia? Javanese? Sundanese? Malay? English? How???\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "Enough the ranting, let's start with data normalization before we going for the actual pre-processing concept for NLU:\n",
        "\n",
        "1. Make all words in the dataset lower case\n",
        "2. Remove any punctuation characters\n",
        "3. Remove Bahasa Indonesia stop words\n",
        "4. Label's One-Hot Encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MN3mzka21Wn"
      },
      "outputs": [],
      "source": [
        "# Call out step 1\n",
        "feature_train = feature_train.str.lower();\n",
        "feature_test = feature_test.str.lower();\n",
        "feature_val = feature_val.str.lower();\n",
        "\n",
        "# Call out step 2\n",
        "def remove_punctuation (text: str):\n",
        "    punct_regex = r'[^\\w\\s]';\n",
        "    clean_text = re.sub(punct_regex, \"\", text);\n",
        "    return clean_text;\n",
        "\n",
        "feature_train = feature_train.apply(lambda x: remove_punctuation(x));\n",
        "feature_test = feature_test.apply(lambda x: remove_punctuation(x));\n",
        "feature_val = feature_val.apply(lambda x: remove_punctuation(x));\n",
        "\n",
        "# Call out step 3\n",
        "stopword_factory = StopWordRemoverFactory();\n",
        "stopwords = stopword_factory.get_stop_words();\n",
        "\n",
        "def remove_stopword (text: str):\n",
        "    # Splice the sentence into words\n",
        "    words = text.split();\n",
        "\n",
        "    # If word in current loop is not available in stopwords array, then save it to clean_words\n",
        "    clean_words = [i for i in words if i not in stopwords];\n",
        "\n",
        "    # Unsplice words into one sentence.\n",
        "    return \" \".join(clean_words);\n",
        "\n",
        "feature_train = feature_train.apply(lambda x: remove_stopword(x));\n",
        "feature_test = feature_test.apply(lambda x: remove_stopword(x));\n",
        "feature_val = feature_val.apply(lambda x: remove_stopword(x));\n",
        "\n",
        "# Call out step 4\n",
        "label_train = pandas.get_dummies(label_train, prefix = \"sentiment_\");\n",
        "label_test = pandas.get_dummies(label_test, prefix = \"sentiment_\");\n",
        "label_val = pandas.get_dummies(label_val, prefix = \"sentiment_\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9NbarTo21Wo"
      },
      "source": [
        "There are few things to complete within dataset pre-processing for NLU case:\n",
        "\n",
        "### 1. Slang Word Standardization\n",
        "We have such beautiful community that keep texting with slang words. In other word, not removing slang-words may cause problems when stemming. So, this part will replace all those slang words, into standard one.\n",
        "\n",
        "But we also had beautiful community that provides such slang dataset.\n",
        "https://github.com/louisowen6/NLP_bahasa_resources/tree/master\n",
        "\n",
        "The algorithm of this task is as follow:\n",
        "\n",
        "> 1. Load `combined_slang_words.json` file\n",
        "> 2. Loop through features data <br />\n",
        "> 2.1 Splice the sentence <br />\n",
        "> 2.2 For every word within sentence <br />\n",
        "> 2.2.1 If this word is found on slang, then replace it with standard one <br />\n",
        "> 2.2.2 Else, ignore. <br />\n",
        "> 2.3 Unsplice the sentence <br />\n",
        "> 3. Save the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq2RdY3V21Wp"
      },
      "outputs": [],
      "source": [
        "slang_db = json.load(open(\"/content/drive/MyDrive/Collab Dataset/nlp-dl-self-assignment/resources/combined_slang_words.json\", \"r\"));\n",
        "\n",
        "def slang_word_standardizer(text: str):\n",
        "    words = text.split();\n",
        "    clean_words = [slang_db.get(i, i) for i in words];\n",
        "\n",
        "    return \" \".join(clean_words);\n",
        "\n",
        "feature_train = feature_train.apply(lambda x: slang_word_standardizer(x));\n",
        "feature_test = feature_test.apply(lambda x: slang_word_standardizer(x));\n",
        "feature_val = feature_val.apply(lambda x: slang_word_standardizer(x));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfT0bKQ021Wp"
      },
      "source": [
        "\n",
        "### 2. Lexical Analysis\n",
        "\n",
        "This step normalize your text. Kind of doing \"standardization\". This step will include *Stemming*.\n",
        "\n",
        "#### Stemming\n",
        "\n",
        "Bahasa Indonesia had so many unnormal words ruling. By mean *unnormal*:\n",
        "\n",
        "| Unnormal word | Stemming result |\n",
        "|---|---|\n",
        "| Memberikan | beri |\n",
        "| Perekonomian | ekonomi |\n",
        "| Pertumbuhan | tumbuh |\n",
        "| Membanggakan | bangga |\n",
        "\n",
        "*Bare with me\n",
        "\n",
        "#### Lemmatization\n",
        "Unfortunately, Sastrawi haven't made for Lemmatization we will skip the lemmatization for now. But if this feature exists, I'll prefer this than just stemming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGYo7MYv21Wq",
        "outputId": "ace260fe-20bf-411b-dddb-5ed6fa904fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stemming feature train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7564/7564 [21:43<00:00,  5.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stemming feature test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1621/1621 [03:12<00:00,  8.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stemming feature val\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1621/1621 [02:59<00:00,  9.01it/s]\n"
          ]
        }
      ],
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory;\n",
        "\n",
        "factory = StemmerFactory();\n",
        "stemmer = factory.create_stemmer();\n",
        "\n",
        "tqdm.pandas();\n",
        "\n",
        "# Apply stemmer\n",
        "print(\"Stemming feature train\");\n",
        "feature_train = feature_train.progress_apply(lambda x: stemmer.stem(x));\n",
        "\n",
        "print(\"Stemming feature test\");\n",
        "feature_test = feature_test.progress_apply(lambda x: stemmer.stem(x));\n",
        "\n",
        "print(\"Stemming feature val\");\n",
        "feature_val = feature_val.progress_apply(lambda x: stemmer.stem(x));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbjzWnpP21Wq"
      },
      "source": [
        "### 3. Tokenization & Vectorization / Word Embedding\n",
        "\n",
        "After Stemming, we will start into Tokenization & Vectorization.\n",
        "\n",
        "#### Tokenization\n",
        "\n",
        "Hence I got this sentence below:\n",
        "\n",
        "\"Hallo everynyan. How are you? Fine thank you. I wish I were a bird.\"\n",
        "\n",
        "I can tokenize things into:\n",
        "\n",
        "`[3, 4, 5, 6, 1, 7, 8, 1, 2, 9, 2, 10, 11, 12]`\n",
        "\n",
        "This can be happen because word `you` in this corpus (sentence) is tokenized as `1` since it is showing two times and shown first. Notice that word `I` denoted as 2. The rest are just less frequently shown so it turned into 3, 4, 5, 6, 7, 8, 9, 10, 11, and 12 respectively.\n",
        "\n",
        "The example above, was a tokenization with 1 word for every respective token.\n",
        "\n",
        "The Tokenization will be done using manual data manipulation. And I choosed to tokenize the corpus word per word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6wDRH9r21Wq",
        "outputId": "04454d00-acba-4265-aa27-d1eac75011d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing feature train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7564/7564 [00:00<00:00, 387016.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing feature test\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1621/1621 [00:00<00:00, 397089.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing feature val\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1621/1621 [00:00<00:00, 407148.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tokenization result sample\n",
            "==============================\n",
            "Normal \t\t\t: kamu ret sabar takkkk aku ipx pon tidak tukar\n",
            "Tokenized version \t: ['kamu', 'ret', 'sabar', 'takkkk', 'aku', 'ipx', 'pon', 'tidak', 'tukar']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Apply tokenization\n",
        "print(\"Tokenizing feature train\");\n",
        "tokenized_train = feature_train.progress_apply(lambda x: x.split());\n",
        "\n",
        "print(\"Tokenizing feature test\");\n",
        "tokenized_test = feature_test.progress_apply(lambda x: x.split());\n",
        "\n",
        "print(\"Tokenizing feature val\");\n",
        "tokenized_val = feature_val.progress_apply(lambda x: x.split());\n",
        "\n",
        "print(\"\\n\\nTokenization result sample\");\n",
        "print(\"==============================\");\n",
        "\n",
        "print(f\"Normal \\t\\t\\t: {feature_train.iloc[0]}\");\n",
        "\n",
        "print(f\"Tokenized version \\t: {tokenized_train.iloc[0]}\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXi2GdeX21Wr"
      },
      "source": [
        "#### Vectorization\n",
        "\n",
        "Since two vectorization function are required, the Vectorization will be done using Word2Vec Skip Gram and Fast Text.\n",
        "\n",
        "After reading fast the dataset, the agreement are as follow:\n",
        "\n",
        "1. Every text within the tweet dataset are not more than 280.\n",
        "2. A tweet are more likely to be pro-found context after reading 8 to 14 words. Since the lowest number from it was 8, so I choose 8.\n",
        "3. The valid tweet is a tweet that has at least 1 word / character.\n",
        "4. Since I don't want to add \"stride\" to the text, I will set the skip gram as 1.\n",
        "\n",
        "Those numbers will be set as configurations below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3Y9BCH6Gzib"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec;\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences;\n",
        "import numpy;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhgALqcPHU-1"
      },
      "outputs": [],
      "source": [
        "# CONFIG\n",
        "tweet_max_size = 280; # Embedding Dims & Max sequence length\n",
        "context_profound = 8; # Window\n",
        "minimum_valid_length = 1; # Minlen\n",
        "skip_gram_config = 1; # Sg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arQBgKkUIsbL"
      },
      "source": [
        "The process of making Word Embedding engine will be performed with OOP technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "R16vlwAe21Wr"
      },
      "outputs": [],
      "source": [
        "# Merge train, test, val data for embedding\n",
        "merged_splits = pandas.concat([tokenized_train, tokenized_test, tokenized_val]);\n",
        "\n",
        "# Using train data, train to embed the data.\n",
        "w2v_model = Word2Vec(\n",
        "    sentences = merged_splits,\n",
        "    vector_size = tweet_max_size,\n",
        "    window = context_profound,\n",
        "    min_count = minimum_valid_length,\n",
        "    workers = 10, # Let's test the A100 machine :3\n",
        "    sg = skip_gram_config\n",
        ");\n",
        "\n",
        "w2v_model.train(merged_splits, total_examples = len(merged_splits), epochs = 25);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_vHy5AYgehf",
        "outputId": "68bf1c46-e6c2-41c5-d3ce-21a4c9152d8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10806"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(merged_splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFLR39FYdMjl",
        "outputId": "90854ad7-3105-4ea4-fe9f-1bf1737e0982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Result\n",
            "=============================\n",
            "Total vocabulary saved: 17674\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Result\");\n",
        "print(\"=============================\");\n",
        "print(f\"Total vocabulary saved: {len(w2v_model.wv)}\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyDdFowwJTGZ"
      },
      "source": [
        "#### Converting word vectors into DNN readable format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKejrFEcLwjA"
      },
      "source": [
        "### Convert data splits into Pad Sequences\n",
        "\n",
        "This endeavor will converting those tokenized sentences into DNN readable format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxE-_eJPLv0u",
        "outputId": "cd611d04-a3e7-443f-b16f-d809bc87191b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7564/7564 [00:00<00:00, 34184.58it/s]\n",
            "100%|██████████| 1621/1621 [00:00<00:00, 33254.59it/s]\n",
            "100%|██████████| 1621/1621 [00:00<00:00, 38045.97it/s]\n"
          ]
        }
      ],
      "source": [
        "# Extract word vectors for each tokenized sequence\n",
        "vectorized_train = [];\n",
        "vectorized_test = [];\n",
        "vectorized_val = [];\n",
        "\n",
        "for split in [tokenized_train, tokenized_test, tokenized_val]:\n",
        "    split_embeddings = [];\n",
        "\n",
        "    for texts in tqdm(split):\n",
        "        sequence_embeddings = [];\n",
        "\n",
        "        sequence_embeddings = [w2v_model.wv[token] if token in w2v_model.wv else [0] * tweet_max_size for token in texts];\n",
        "        numpy_embedding = numpy.array(sequence_embeddings);\n",
        "        split_embeddings.append(numpy_embedding);\n",
        "\n",
        "    # Pad or truncate sequences to make them uniform in length\n",
        "    padded_sequences = pad_sequences(\n",
        "        split_embeddings,\n",
        "        maxlen = tweet_max_size,\n",
        "        padding = \"post\",\n",
        "        truncating = \"post\",\n",
        "        dtype='float32'\n",
        "    );\n",
        "\n",
        "    if(split is tokenized_train):\n",
        "        vectorized_train = padded_sequences;\n",
        "    elif(split is tokenized_test):\n",
        "        vectorized_test = padded_sequences;\n",
        "    else:\n",
        "        vectorized_val = padded_sequences;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OQPvhbvMzwB"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zg_o1ji21Ws"
      },
      "source": [
        "## Model Architecture\n",
        "\n",
        "This is where Model Architecture being implemented. As usual, the implementation of Model Architecture will be done using OOP technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60DpaWk3U0UU",
        "outputId": "f0f74224-c01f-4b2c-dfa0-7651bb189ad6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7564, 280, 280), 17674, (17674, 280))"
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_weight = w2v_model.wv.vectors;\n",
        "\n",
        "vectorized_train.shape, len(w2v_model.wv), w2v_weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "_kNW-hw721Ws"
      },
      "outputs": [],
      "source": [
        "import tensorflow;\n",
        "from tensorflow.keras.models import Sequential;\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, BatchNormalization, LSTM, Bidirectional, Flatten, TimeDistributed, Reshape;\n",
        "\n",
        "import matplotlib.pyplot as plt;\n",
        "\n",
        "from tensorflow.keras.utils import plot_model;\n",
        "from tensorflow.keras.callbacks import EarlyStopping;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "_PgDzh7h8d2n"
      },
      "outputs": [],
      "source": [
        "class BLSTMModel:\n",
        "  def __init__(self):\n",
        "    self.input = Input(shape=(tweet_max_size,));\n",
        "    self.embedding = Embedding(\n",
        "        input_dim = len(w2v_model.wv),\n",
        "        weights = [w2v_weight],\n",
        "        output_dim = tweet_max_size,\n",
        "        name = \"embedding\"\n",
        "    );\n",
        "\n",
        "    self.encoder = Bidirectional(\n",
        "        LSTM(\n",
        "            units = 512,\n",
        "            activation = \"tanh\",\n",
        "            recurrent_initializer = 'glorot_uniform',\n",
        "            return_sequences = True),\n",
        "        name = \"encoder\"\n",
        "    );\n",
        "\n",
        "    self.decoder = LSTM(\n",
        "        units = 256,\n",
        "        activation = \"tanh\",\n",
        "        recurrent_initializer = 'glorot_uniform',\n",
        "        return_sequences = True,\n",
        "        name = \"decoder\"\n",
        "    );\n",
        "\n",
        "    # self.bn1 = BatchNormalization(name = \"bn1\");\n",
        "    self.dense1 = Dense(128, activation = \"relu\", name = \"dense1\");\n",
        "    self.output = TimeDistributed(Dense(3, activation = \"softmax\", name = \"output\"));\n",
        "\n",
        "  # Early stopping after loss are not improved for some epochs\n",
        "  def _callback_early_stopping(self):\n",
        "      early_stopping_tolerance = 10;\n",
        "      return EarlyStopping(\n",
        "          monitor = \"val_accuracy\",\n",
        "          patience = early_stopping_tolerance,\n",
        "          restore_best_weights = True\n",
        "      );\n",
        "\n",
        "  def build_model(self):\n",
        "      model = Sequential(name = \"blstm.202405012148\");\n",
        "\n",
        "      model.add(self.input);\n",
        "\n",
        "      model.add(self.embedding);\n",
        "\n",
        "\n",
        "      model.add(self.encoder);\n",
        "      model.add(self.decoder);\n",
        "\n",
        "      # model.add(self.bn1);\n",
        "\n",
        "      model.add(self.dense1);\n",
        "      model.add(self.output);\n",
        "\n",
        "      model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"]);\n",
        "\n",
        "      return model;\n",
        "\n",
        "  def fitting(self):\n",
        "      model = self.build_model();\n",
        "      model.summary();\n",
        "\n",
        "      plot_model(model, to_file = (\"model_architecture.png\"), show_shapes = True);\n",
        "\n",
        "\n",
        "      history = model.fit(\n",
        "          vectorized_train,\n",
        "          label_train,\n",
        "          epochs = 300,\n",
        "          batch_size = 64,\n",
        "          validation_data = (vectorized_val, label_val),\n",
        "          callbacks = [self._callback_early_stopping()]\n",
        "      );\n",
        "\n",
        "      # Plot training history\n",
        "      plt.plot(history.history['loss'], label='Training Loss');\n",
        "      plt.plot(history.history['val_loss'], label='Validation Loss');\n",
        "      plt.xlabel('Epoch');\n",
        "      plt.ylabel('Loss');\n",
        "      plt.legend();\n",
        "      plt.show();\n",
        "\n",
        "      return model;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5Z73d8B9K52A",
        "outputId": "69969a0a-9eed-4e2a-ec19-a3238e8ab18f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"blstm.202405012148\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 280, 280)          4948720   \n",
            "                                                                 \n",
            " decoder (LSTM)              (None, 280, 256)          549888    \n",
            "                                                                 \n",
            " dense1 (Dense)              (None, 280, 128)          32896     \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDi  (None, 280, 3)            387       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5531891 (21.10 MB)\n",
            "Trainable params: 5531891 (21.10 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'blstm.202405012148' (type Sequential).\n    \n    Input 0 of layer \"decoder\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 280, 280, 280)\n    \n    Call arguments received by layer 'blstm.202405012148' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 280, 280), dtype=float32)\n      • training=True\n      • mask=None\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-257-d242750e86ca>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mblstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test accuracy BLSTM: {test_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-256-0af67c9114b6>\u001b[0m in \u001b[0;36mfitting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m       history = model.fit(\n\u001b[0m\u001b[1;32m     69\u001b[0m           \u001b[0mvectorized_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'blstm.202405012148' (type Sequential).\n    \n    Input 0 of layer \"decoder\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 280, 280, 280)\n    \n    Call arguments received by layer 'blstm.202405012148' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 280, 280), dtype=float32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "blstm = BLSTMModel();\n",
        "model = blstm.fitting();\n",
        "\n",
        "test_loss, test_acc = model.evaluate(vectorized_test, label_test)\n",
        "print(f'Test accuracy BLSTM: {test_acc}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
